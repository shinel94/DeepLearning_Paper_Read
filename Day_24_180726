1. 다양한 방향으로 stacked 된 LSTM
  1.1 장기의존성을 가진 데이터를 분석하기 위해서 LSTMㅇ 제안되었다.
  1.2 1차원으로 stacked 된 LSTM은 Highway network와 유사한 모습을 나타낸다고 생각 할 수 있다.
  1.3 지난번 hidden node vector와 이번 input vector를 concatenation해서 이번 hidden node input을 만든다.
  1.4 concatenation함으로써 수식 표현이 보다 간단해 진다.
  1.5 기존의 stacked LSTM은 수직방향으로는 hidden node 데이터와 memory cell 데이터가 전파되지 않는다. 오직 output vector만 전파된다.
  1.6 Multidimensional LSTM의 경우는 입력받는 데이터가 벡터 1개가 아닌 N개의 벡터를 동시에 받아서 N개의 병렬로 구성된 LSTM을 이용하는 개념과 비슷하다.
    1.6.1 하나의 긴 벡터의 인풋을 받는것 보다 파라미터 수를 줄일 수 있는것 같다.
    1.6.2 이때 입력데이터의 크기가 커질수록 모델의 instability가 커진다.
    1.6.3 memory cell이 데이터를 한번에 저장하게 모델을 학습하기 때문
  1.7 GRID LSTM은 입력의 deimension에 상관없게 적용할 수 있고, depth도 설정할 수 있는 LSTM이다.
    1.7.1 본 모델에서는 입력은 모든 Hidden vector를 concate해서 들어가지만 출력은 각각 벡터에 따른 hidden node vector와 memory cell 벡터가 출력되게 N개의 모델을 학습한다.
    1.7.2 k번째 벡터를 계산하는 LSTM의 hidden node data는 이번 k번째 입력을 제외하고 나머지는 모두 지난번 출력을 설정한다.
    1.7.3 추가적인 data input이 없이 hidden node와 memory cell들이 전파된다.
    1.7.4 모든 hidden node들이 LSTM을 통과할 필요가 없기 때문에, 다음 hidden node는 하나의 추가적인 perceptron으로 N*d의 벡터를 d 사이즈의 벡터로 압축한다.
  1.8 다양한 dimension으로 가중치를 share해서 computation을 줄일 수 있다.
  1.9 가중치를 공유한 Tied 2 LSTM이 장기의존성에 대한 정보를 잘 기억하는것을 확인 할 수 있다.
  1.10 번역전 데이터를 입력으로 번역후 데이터를 출력으로 그리고 동시에 bidirection 데이터를 처리하게 2차원 data로 넣어서 3차원 LSTM을 적용하면 translation에서도 좋은 성능을 얻을 수 있다.
  1.11 https://arxiv.org/abs/1507.01526
