1. Attention please
  1.1 sequence를 transduction 하는 모델이 많이 제안되었다.
  1.2 LSTM이나 GRU와 같은 RNN이나 encoder - decoder구조를 가지고 있는 CNN이 제안되었다.
  1.3 RNN은 지난먼 출력 h와 이번 입력 x를 이용해서 출력을 계산하는 모델이라서 데이터 처리를 병렬로 하는것이 불가능 해졌다.
  1.4 이는 입력이 아주 길고 큰 sequence일때 심각한 문제가 발생한다.
  1.5 RNN모델에 parallelization을 적용하기 위해서 제안 되었다. 데이터 input output간 global한 dependecy를 찾으려는 것을 피한다.
  1.6 Trasnfomer 모델의 구조는 입력 데이터를 encoding하는 구조와 decoder구조를 가지는데 이번 입력에 대해서 압축된 값과 지난번 출력값을 이용해서 sequence를 압축한다.
  1.7 encoder는 self multi head intension block과 feed forward block 두개가 하나로 구성되었고 Residual connection이 각 block에 연결되어 있고 layer normalization이 적용되는 module이 6개 겹쳐져 있다.
  1.8 decoder는 encoder에서 들어온 데이터와 지난번 decoder의 출력을 모두 입력으로 받는데 지난번 step에서 넘어온 출력은 masked multi head attention block을 먼저 한번 통과시키고 이후에 입너 입력과 encoder와 비슷한 구조를 통과시킨뒤 신경망을 통과시켜 softmax를 처리한다.
  1.9 attention의 입력은 Query, Key, Value가 pair로 구성되어서 입력이 들어간다.
  1.10 이때 query와 key를 통해서 attention할 value를 계산한다.
  1.11 이 attention block이 palallel하게 여러개 연결 되어 있으면 multi head attention block이 된다.
  1.12 attention의 query가 지난번 encoder의 출력에서 나오면 self-attention layer 가되고 이번 block의 입력에 포함 되어 있으면 encoder decoder attention이 되어서 query가 모든 layer에서 일정하게 들어간다.
  1.13 입력과 출력을 embbeding해서 tokenization해서 성능을 올릴 수 있다.
  1.14 self attention을 사용하면 계산복잡도도 줄어들고, 계산을 병렬화 처리 시킬수 있고, path length between long range dependecy에도 좋다.
    1.14.1 이떄 self attention은 자기 데이터를 이용해서 embbeding이나 tokenization을 통해서 query와 key value를 각각 학습해서 계산해낸다.
  1.15 https://arxiv.org/abs/1706.03762

2. RNN based LM
  2.1 RNN이 backoff language model보다 월등히 좋은 성능을 보여준다.
  2.2 우선 language model의 목표는 context data를 이용해서 다음에 올 word를 predict하는 것이 궁극적인 목표이다.
  2.3 기본적인 MLP와 같은 NN으로 fixed length로 입력을 고쳐서 넣으면 비교적 좋은 성능을 나타낸다.
  2.4 그리고 RNN은 입력의 길이가 arbitary한 수로 정할 수 있다. 하지만 RNN 은 long term dependecy를 catch하기 힘들다는 문제가 있다.
  2.5 이번 입력과 지난번 layer의 state 출력을 concate 시킨벡터를 입력으로 하는 RNN을 구성한다.
  2.6 rare한 단어의 출현 확률은 특정 threshold값을 정해서 보다 가중치를 더주어서 확률을 보정한다.
  2.7 이렇게 가중치를 추가해서 RNN을 통해 Language modling task를 apply하면 얘전에 제안되었던 model들보다 성능이 개선된다.
  2.8 http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf

3. 이미지 트래킹을 하는 대신 colorization을 해서 그 효과를 얻자
  3.1 video data를 gray scale로 변형시켜서 첫번째 reference frame을 기준으로 나머지 frame을 colorization하는 모델을 학습하면 object tracking, segmaent tracking, pose detection과 같은 복잡한 기능을 가진 모델을 학습 할 수 있다.
  3.2 이때 여러가지 task를 위해서 추가적인 fine tuning을 할 필요가 없다.
  3.3 첫번째 프레임 데이터를 low embbeding matrix로 압축을 하고나서, 해당 embbeding matrix를 reference로 진행
  3.4 특정 시간대의 frame의 데이터도 embbeding을 진행하고, 각 fixel data를 통해서 inner product softmax로 similarity matrix를 찾고 해당 변형을 통해서 object를 tracking할 수 있다.
  3.5 tracking을 해서, colorization도 진행 할 수 있다.
  3.6 target의 color data를 잘 묘사할 수 있게 이때 color는 클러스터링으로 숫자를 줄여서 colorization을 진행한다.
  3.7 이 color quntization data의 L2 distance를 error로 설정해서 backpropaation을 진행한다.
  3.8 논문에 제안된 모델은 ResNet을 사용하고 동영상의 크기를 256x256으로 자르고 4frame을 기준으로 처음 3개의 frame이 reference frame이 되고 마지막 4번째 frame이 target frame이 되서 target을 colorization한다.
  3.9 동영상 1초당 6장의 프레임을 사용했다.
  3.10 이를 통해서 colorization하고, feature map을 통해서 similarity를 잘 계산하면 제안된 모델이 입력 데이터에 상관없이 robust를 가지는 모델인 것으로 확인된다.
  3.11 같은 모델을 통해서 colorization task와 tracking task를 진행시켰는데 둘의 실패나 성공정도가 비슷한것으로 나타난다.
  3.12 하나의 labelled되지 않은 비디오 데이터에서 reference frame을 설정해서 self supervised laerning이 가능하며, 이를 통해서 colorization, tracking, pose detecting과 같은 복잡한 task를 하나의 모델로 처리 할 수 있다.
  3.13 https://arxiv.org/abs/1806.09594
