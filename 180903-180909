1. DeepID-Net
  1.1 CNN을 학습할때 각 layer의 출력을 이용해서 stage by stage로 학습을 진행할 수 있게 했고, 단순한 max, avg pooling이 아닌 객체가 filter 중심에서 멀어질수록 결과값에 가중치를 부가해서 deformation에 대해서 더 잘 학습할 수 있게 했고, 같은 모델에 다양한 방법을 적용해서 여러개의 모델을 ensemble해서 성능을 향상 시킬 수 있다.
    1.1.1 stage by stage가 하단 layer에서 학습이 된 결과값을 그대로 사용하고, 상위 layer에서 학습할때는 하위 layer의 가중치가 변화되지 않게 한다.
    1.1.2 기존의 CNN은 avg 나 max pooling을 통해서 feature map을 압축하게 되는데, 이렇게 데이터를 처리하게 되면 deformation이나 aspect ratio나 객체의 위치 어디에 있든 같은 결과값을 나타내게 되는데 이는 우리의 직관과는 약간 다르게 된다.
    1.1.3 이를 해결하기 위해서 bounding box에서 이미지의 위치를 확인하고 이미지의 위치에 따라서 panalty를 추가해서 학습을 진행해서 모델의 성능을 향상 시킨다.
    1.1.4 모든 layer의 출력을 이용해서 feature map을 추출해서 학습을 진행하면 더 좋은 성능을 내는 것을 확인 할 수 있다.

2. Single Shot MultiBox Detector
  2.1 하나의 이미지에서 bounding box를 여러개 미리 defualt로 설정해두고 그 bounding box별로 image가 있는 확률을 계산해서 classification을 진행하는데 이떄 multi class로 분류를 해야되기 때문에, positive sample의 갯수보다 자연적으로 negative sample이 많기 때문에, 이를 해결하기 위해서 loss term의 cross entropy term에 negative sample의 데이터도 학습할때 일정비률로 추가하고 이떄 positive sample의 확률 역시 1로 하는 것이 아닌 학습으로 진행되게 해서 보다 학습이 잘되게 했다. 그리고 이를 통해서 모데르이 성능이 향상되었고, YOLO와 달리 sliding window방식이 아니라서 학습도 빠르고 모델의 robustness도 높다. 그리고 data의 입력하기 전에 진행되는 augmentation이 모델의 성능향상에 많은 영향을 끼친다.
    2.1.1 VGG16으로 이미지의 feature map을 얻어낸 다음, 얻은 feature map에 다양한 bounding box를 적용하는데 결국에 sliding window일것 같지만 sliding window는 아니라고 한다.
    2.1.2 VGG16의 출력값을 base로 해서 추가적으로 embedding이 진행되고 각 embedding된 feature map을 auxiliary structure로서 학습을 진행해서 보다 학습을 잘 되게 했다.
    2.1.3 그리고 bounding box별로 data를 얻어서 classification을 진행해서 모델의 성능을 향상한다.
    2.1.4 이때 layer와 box별로 이미지가 있는지 없는지를 비교해서 loss function이 구성되게 되고, positive sample만 이용하는 것이 아닌 negative sample을 함께 진행해서 학습 속도를 증진 시킬 수 있게 했다.
    2.1.5 그리고 입력데이터 즉 이미지 사이즈가 커질 수록 모델의 성능이 향상되는 것을 확인 할 수 있는데, 이는 당연한 결과로 이미지가 커질 수록 이미지가 가질 수 있는 데이터의 총량도 증가하게 되고, 이를 통해서 분류를 진행할 데이터를 더 많이 얻어 낼 수 있게 된다. 하지만 대부분의 경우 이미지가 커질 수록 분류를 잘 못하게 되었지만 본 모델에서는 입력데이터가 커지면서 성능이 향상되는 결과를 얻을 수 있었고, 추가적으로 성능을 향상시킬 여지가 있는것으로 생각된다.
    2.1.6 Data Augmentation이 모델의 robustness가 향상되고 모델의 전반적인 성능이 향상되게 된다.

3. OHEM
  3.1 RoI Pooling을 이용해서 image에 obeject가 있는지 그리고 baground가 얼마나 되는지를 확인해서, 이 데이터를 이용해서 학습이 잘 진행 될 수 있는 데이터를 선택해서 모델이 학습될 데이터로 선택해서 학습을 진행해서 모델이 보다 빠르고 robustness가 높게 모델을 학습 할 수 있다.
    3.1.1 기본적인 아이디어는 bootstraping의 방식을 이용하는 것으로 model이 학습을 잘시키기 위해서, 학습을 잘 할 수 있는 좋은 예제를 선택해서 학습을 진행하자는 목표를 가지고 있다.
    3.1.2 이방법을 이용하면 Region-based ConvNet detector에 모두 적용을 할 수 있게 되고, RoI데이터를 이용해서 OHEM을 진행하게 되면서 모델이 더 학습이 잘되게 만들 수 있다.
    
