1. RNN 2개를 cascade하게 놓아서 autoencoder 처럼 행동하게 하면 word의 sementic하고 syntatic한 의미를 캐치할 수 있다.
  1.1 RNN - Encoder와 Decoder로 단어의 의미를 파악 할 수있다.
  1.2 인풋이 있이 주어졌을때 출력이 정해지는데 중간의 고정된 길이의 벡터로 압축을 하고 이를 다시 복원한다.
  1.3 이때 입력이 영어 출력이 프랑스어와 같이 번역에 사용 할 수 있다.
  1.4 특정 길이의 압축된 벡터를 이용하면 단어의 의미를 나타내는 수치적인 벡터를 얻을 수 있다.
  1.5 하나의 신경망으로 machine translation이랑 word representation을 할 수 있다
  1.6 https://arxiv.org/abs/1406.1078

2. bagging의 효과를 얻을 수 있는 maxout
  2.1 dropout의 경우와 비슷하게 maxout을 이용하면 bagging의 요과 ensemble model의 효과를 볼 수 있다.
  2.2 dropout의 경우에는 일부러 node의 결과를 0으로 만들기 때문에, 학습속도가 지나치게 저하된다.
  2.3 특히 gradient가 saturation되는 문제가 발생한다.
  2.4 하지만 maxout의 경우에는 gradient가 0이 되는 일이 없다.
  2.5 모든 parameter들을 공유할 수 있다.
  2.6 여러개의 모델을 만들고 그들의 결과값중 최댓값을 뽑아낸다. maxpooling
  2.7 https://arxiv.org/pdf/1302.4389.pdf
